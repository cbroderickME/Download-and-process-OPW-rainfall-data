{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing station: 80709\n",
      "Extracted to K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\extracted\\80709\n",
      "Processing file: K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\extracted\\80709\\tsvalues.csv\n",
      "Metadata: {'ID': '80709', 'Name': 'Ballinatona Water Treatment Plant', 'Latitude': '52.25785307', 'Longitude': '-9.05015031'}\n",
      "Saved hourly data: K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\processed\\80709_hourly.csv | Rows: 161128\n",
      "Saved daily 09Z→09Z data: K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\processed\\80709_daily_09Z.csv | Rows: 6715\n",
      "Saved daily 00Z→23:59 data: K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\processed\\80709_daily_UTC.csv | Rows: 6715\n",
      "Saved metadata: K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\metadata\\80709_metadata.csv\n",
      "\n",
      "Processing station: 81903\n",
      "Extracted to K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\extracted\\81903\n",
      "Processing file: K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\extracted\\81903\\tsvalues.csv\n",
      "Metadata: {'ID': '81903', 'Name': 'Ballingeary', 'Latitude': '51.856816', 'Longitude': '-9.233312'}\n",
      "Saved hourly data: K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\processed\\81903_hourly.csv | Rows: 34038\n",
      "Saved daily 09Z→09Z data: K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\processed\\81903_daily_09Z.csv | Rows: 1419\n",
      "Saved daily 00Z→23:59 data: K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\processed\\81903_daily_UTC.csv | Rows: 1419\n",
      "Saved metadata: K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\metadata\\81903_metadata.csv\n",
      "\n",
      "Processing station: 80711\n",
      "Extracted to K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\extracted\\80711\n",
      "Processing file: K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\extracted\\80711\\tsvalues.csv\n",
      "Metadata: {'ID': '80711', 'Name': 'Ballydesmond Pump house', 'Latitude': '52.18033378', 'Longitude': '-9.242978537'}\n",
      "Saved hourly data: K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\processed\\80711_hourly.csv | Rows: 156614\n",
      "Saved daily 09Z→09Z data: K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\processed\\80711_daily_09Z.csv | Rows: 6527\n",
      "Saved daily 00Z→23:59 data: K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\processed\\80711_daily_UTC.csv | Rows: 6527\n",
      "Saved metadata: K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\metadata\\80711_metadata.csv\n",
      "\n",
      "Processing station: 80722\n",
      "Extracted to K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\extracted\\80722\n",
      "Processing file: K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\extracted\\80722\\tsvalues.csv\n",
      "Metadata: {'ID': '80722', 'Name': 'Ballyguyroe Landfill Site', 'Latitude': '52.28205466', 'Longitude': '-8.495350706'}\n",
      "Saved hourly data: K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\processed\\80722_hourly.csv | Rows: 161104\n",
      "Saved daily 09Z→09Z data: K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\processed\\80722_daily_09Z.csv | Rows: 6714\n",
      "Saved daily 00Z→23:59 data: K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\processed\\80722_daily_UTC.csv | Rows: 6714\n",
      "Saved metadata: K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\metadata\\80722_metadata.csv\n",
      "\n",
      "Processing station: 80707\n",
      "Extracted to K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\extracted\\80707\n",
      "Processing file: K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\extracted\\80707\\tsvalues.csv\n",
      "Metadata: {'ID': '80707', 'Name': 'Ballyhoura Way Water Intake Works', 'Latitude': '52.279505', 'Longitude': '-8.69043799'}\n",
      "Saved hourly data: K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\processed\\80707_hourly.csv | Rows: 161103\n",
      "Saved daily 09Z→09Z data: K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\processed\\80707_daily_09Z.csv | Rows: 6714\n",
      "Saved daily 00Z→23:59 data: K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\processed\\80707_daily_UTC.csv | Rows: 6714\n",
      "Saved metadata: K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\metadata\\80707_metadata.csv\n",
      "\n",
      "Processing station: 81633\n",
      "Extracted to K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\extracted\\81633\n",
      "Processing file: K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\extracted\\81633\\tsvalues.csv\n",
      "Metadata: {'ID': '81633', 'Name': 'Ballylanders', 'Latitude': '52.364629', 'Longitude': '-8.326127'}\n",
      "Saved hourly data: K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\processed\\81633_hourly.csv | Rows: 47862\n",
      "Saved daily 09Z→09Z data: K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\processed\\81633_daily_09Z.csv | Rows: 1995\n",
      "Saved daily 00Z→23:59 data: K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\processed\\81633_daily_UTC.csv | Rows: 1995\n",
      "Saved metadata: K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\metadata\\81633_metadata.csv\n",
      "\n",
      "Processing station: 81610\n",
      "Extracted to K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\extracted\\81610\n",
      "Processing file: K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\extracted\\81610\\tsvalues.csv\n",
      "Metadata: {'ID': '81610', 'Name': 'Ballymacarbry Council Depot', 'Latitude': '52.280032', 'Longitude': '-7.73594099'}\n",
      "Saved hourly data: K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\processed\\81610_hourly.csv | Rows: 177092\n",
      "Saved daily 09Z→09Z data: K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\processed\\81610_daily_09Z.csv | Rows: 7380\n",
      "Saved daily 00Z→23:59 data: K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\processed\\81610_daily_UTC.csv | Rows: 7380\n",
      "Saved metadata: K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\metadata\\81610_metadata.csv\n",
      "\n",
      "Processing station: 81202\n",
      "Extracted to K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\extracted\\81202\n",
      "Processing file: K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\extracted\\81202\\tsvalues.csv\n",
      "Metadata: {'ID': '81202', 'Name': 'Ballynagee', 'Latitude': '52.3262', 'Longitude': '-6.4818'}\n",
      "Saved hourly data: K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\processed\\81202_hourly.csv | Rows: 16926\n",
      "Saved daily 09Z→09Z data: K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\processed\\81202_daily_09Z.csv | Rows: 706\n",
      "Saved daily 00Z→23:59 data: K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\processed\\81202_daily_UTC.csv | Rows: 706\n",
      "Saved metadata: K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\metadata\\81202_metadata.csv\n",
      "\n",
      "Processing station: 81604\n",
      "Extracted to K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\extracted\\81604\n",
      "Processing file: K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\extracted\\81604\\tsvalues.csv\n",
      "Metadata: {'ID': '81604', 'Name': 'Ballyporeen Reservoir', 'Latitude': '52.28805856', 'Longitude': '-8.125494157'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "# -----------------------------\n",
    "# Paths\n",
    "# -----------------------------\n",
    "# Define file paths for station overview, extracted files, processed data, metadata, and downloads\n",
    "station_overview_path = r\"K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\scripts\\station_overview_table_250217.csv\"\n",
    "extract_base_path     = r\"K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\extracted\"\n",
    "processed_path        = r\"K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\processed\"\n",
    "metadata_path         = r\"K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\metadata\"\n",
    "download_path         = r\"K:\\Fluvial\\Meteorological_Data\\Rainfall\\OPW\\zips\"\n",
    "\n",
    "# Make folders if they don't exist\n",
    "os.makedirs(extract_base_path, exist_ok=True)\n",
    "os.makedirs(processed_path, exist_ok=True)\n",
    "os.makedirs(metadata_path, exist_ok=True)\n",
    "os.makedirs(download_path, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Load station overview\n",
    "# -----------------------------\n",
    "# Read CSV containing station numbers to process\n",
    "station_overview = pd.read_csv(station_overview_path)\n",
    "\n",
    "# -----------------------------\n",
    "# Loop through stations\n",
    "# -----------------------------\n",
    "# For each station:\n",
    "#   - Create extraction folder\n",
    "#   - Download ZIP if missing\n",
    "#   - Extract ZIP\n",
    "#   - Process CSV for metadata and rainfall values\n",
    "for station in station_overview[\"Station\"]:\n",
    "    station_str = str(station)\n",
    "    print(f\"\\nProcessing station: {station_str}\")\n",
    "\n",
    "    # Create folder for extracted files\n",
    "    extract_path = os.path.join(extract_base_path, station_str)\n",
    "    os.makedirs(extract_path, exist_ok=True)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Download ZIP if not already present\n",
    "    # -----------------------------\n",
    "    zip_file = os.path.join(download_path, f\"{station_str}.zip\")\n",
    "    if not os.path.exists(zip_file):\n",
    "        url = f\"https://waterlevel.ie/hydro-data/data/internet/stations/0/{station_str}/Precip/Rainfall_complete.zip\"\n",
    "        print(f\"Downloading {station_str}...\")\n",
    "        try:\n",
    "            r = requests.get(url)\n",
    "            r.raise_for_status()\n",
    "            with open(zip_file, 'wb') as f:\n",
    "                f.write(r.content)\n",
    "            print(f\"Downloaded zip for station {station_str}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to download {station_str}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # -----------------------------\n",
    "    # Extract ZIP\n",
    "    # -----------------------------\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_path)\n",
    "        print(f\"Extracted to {extract_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to extract {station_str}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # -----------------------------\n",
    "    # Locate tsvalues CSV\n",
    "    # -----------------------------\n",
    "    # Find the CSV file inside extracted folder\n",
    "    csv_files = glob.glob(os.path.join(extract_path, \"*.csv\"))\n",
    "    if not csv_files:\n",
    "        print(f\"No CSV found for station {station_str}\")\n",
    "        continue\n",
    "    csv_file_path = csv_files[0]\n",
    "    print(f\"Processing file: {csv_file_path}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Read metadata\n",
    "    # -----------------------------\n",
    "    # Extract station ID, name, latitude, longitude from CSV header\n",
    "    tsvalues_meta = pd.read_csv(csv_file_path, nrows=5, sep=';', index_col=0, names=['Attribute', 'Value'])\n",
    "    metadata_stat = {\n",
    "        'ID': tsvalues_meta.loc['#station_no','Value'],\n",
    "        'Name': tsvalues_meta.loc['#station_name','Value'],\n",
    "        'Latitude': tsvalues_meta.loc['#station_latitude','Value'],\n",
    "        'Longitude': tsvalues_meta.loc['#station_longitude','Value']\n",
    "    }\n",
    "    print(\"Metadata:\", metadata_stat)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Read rainfall time series\n",
    "    # -----------------------------\n",
    "    # Separate rainfall values and quality codes\n",
    "    # Convert timestamps to datetime and set as index\n",
    "    df = pd.read_csv(csv_file_path, sep=';', skiprows=8)\n",
    "    df_values  = df[['#Timestamp','Value']].copy()\n",
    "    df_quality = df[['#Timestamp','Quality Code']].copy()\n",
    "    df_values['#Timestamp'] = pd.to_datetime(df_values['#Timestamp'])\n",
    "    df_quality['#Timestamp'] = pd.to_datetime(df_quality['#Timestamp'])\n",
    "    df_values.set_index('#Timestamp', inplace=True)\n",
    "    df_quality.set_index('#Timestamp', inplace=True)\n",
    "\n",
    "    # Filter out missing values marked as -99\n",
    "    df_values = df_values[df_values['Value'] != -99]\n",
    "\n",
    "    # -----------------------------\n",
    "    # Hourly aggregation\n",
    "    # -----------------------------\n",
    "    # Sum 15-min values into hourly totals\n",
    "    # Mark hour as -99 if any 15-min value is invalid\n",
    "    hourly_sum = df_values['Value'].resample('h').sum()\n",
    "    hourly_count_valid = df_quality['Quality Code'].resample('h').apply(lambda x: (x==254).all())\n",
    "    hourly_sum[~hourly_count_valid] = -99\n",
    "\n",
    "    # Ensure complete hourly index\n",
    "    full_hour_index = pd.date_range(start=hourly_sum.index.min(),\n",
    "                                    end=hourly_sum.index.max(),\n",
    "                                    freq='h')\n",
    "    hourly_sum = hourly_sum.reindex(full_hour_index, fill_value=-99)\n",
    "\n",
    "    df_hourly = hourly_sum.to_frame(name='rainfall').reset_index()\n",
    "    df_hourly.rename(columns={'index':'time'}, inplace=True)\n",
    "    df_hourly['stno'] = metadata_stat['ID']\n",
    "    df_hourly = df_hourly[['time','stno','rainfall']]\n",
    "\n",
    "    # Save hourly CSV\n",
    "    path_hourly = os.path.join(processed_path, f\"{station_str}_hourly.csv\")\n",
    "    df_hourly.to_csv(path_hourly, index=False)\n",
    "    print(f\"Saved hourly data: {path_hourly} | Rows: {df_hourly.shape[0]}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Daily aggregation 09Z→09Z\n",
    "    # -----------------------------\n",
    "    # Sum rainfall from 09:00 of one day to 08:59:59 of next day\n",
    "    daily_records_09Z = []\n",
    "    first_day = df_values.index.min().normalize() + pd.Timedelta(hours=9)\n",
    "    last_day  = df_values.index.max().normalize() + pd.Timedelta(hours=9)\n",
    "\n",
    "    current_day = first_day\n",
    "    while current_day <= last_day:\n",
    "        day_start = current_day\n",
    "        day_end   = day_start + pd.Timedelta(hours=24)\n",
    "\n",
    "        df_day_values  = df_values.loc[day_start:day_end - pd.Timedelta(seconds=1)]\n",
    "        df_day_quality = df_quality.loc[day_start:day_end - pd.Timedelta(seconds=1)]\n",
    "\n",
    "        if not df_day_values.empty and (df_day_quality['Quality Code'] == 254).all():\n",
    "            value = df_day_values['Value'].sum()\n",
    "        else:\n",
    "            value = -99\n",
    "\n",
    "        daily_records_09Z.append({'date': day_start.date(), 'stno': metadata_stat['ID'], 'rainfall': value})\n",
    "        current_day += pd.Timedelta(days=1)\n",
    "\n",
    "    df_daily_09Z = pd.DataFrame(daily_records_09Z)\n",
    "    path_daily_09Z = os.path.join(processed_path, f\"{station_str}_daily_09Z.csv\")\n",
    "    df_daily_09Z.to_csv(path_daily_09Z, index=False)\n",
    "    print(f\"Saved daily 09Z→09Z data: {path_daily_09Z} | Rows: {df_daily_09Z.shape[0]}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Daily aggregation 00Z→23:59\n",
    "    # -----------------------------\n",
    "    # Sum rainfall from 00:00 to 23:59:59 UTC\n",
    "    daily_records_UTC = []\n",
    "    first_day_UTC = df_values.index.min().normalize()\n",
    "    last_day_UTC  = df_values.index.max().normalize()\n",
    "\n",
    "    current_day = first_day_UTC\n",
    "    while current_day <= last_day_UTC:\n",
    "        day_start = current_day\n",
    "        day_end   = day_start + pd.Timedelta(days=1) - pd.Timedelta(seconds=1)\n",
    "\n",
    "        df_day_values  = df_values.loc[day_start:day_end]\n",
    "        df_day_quality = df_quality.loc[day_start:day_end]\n",
    "\n",
    "        if not df_day_values.empty and (df_day_quality['Quality Code'] == 254).all():\n",
    "            value = df_day_values['Value'].sum()\n",
    "        else:\n",
    "            value = -99\n",
    "\n",
    "        daily_records_UTC.append({'date': day_start.date(), 'stno': metadata_stat['ID'], 'rainfall': value})\n",
    "        current_day += pd.Timedelta(days=1)\n",
    "\n",
    "    df_daily_UTC = pd.DataFrame(daily_records_UTC)\n",
    "    path_daily_UTC = os.path.join(processed_path, f\"{station_str}_daily_UTC.csv\")\n",
    "    df_daily_UTC.to_csv(path_daily_UTC, index=False)\n",
    "    print(f\"Saved daily 00Z→23:59 data: {path_daily_UTC} | Rows: {df_daily_UTC.shape[0]}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Save metadata\n",
    "    # -----------------------------\n",
    "    # Save station metadata as CSV\n",
    "    metadata_output_path = os.path.join(metadata_path, f\"{station_str}_metadata.csv\")\n",
    "    pd.DataFrame([metadata_stat]).to_csv(metadata_output_path, index=False)\n",
    "    print(f\"Saved metadata: {metadata_output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
